{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:00.120354Z",
     "start_time": "2025-05-23T10:37:58.132976Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:00.334996Z",
     "start_time": "2025-05-23T10:38:00.307188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(torch.__version__)              # 2.5.1+cu118\n",
    "print(torch.cuda.is_available())      # True\n",
    "print(torch.cuda.get_device_name(0))  # Your GPU name"
   ],
   "id": "73c4aebcbca40e2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu118\n",
      "True\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Prep",
   "id": "d8fe90f69eaa9f29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:00.365382Z",
     "start_time": "2025-05-23T10:38:00.351349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_paths = {\n",
    "    \"TomQuality\": \"D:/Bitchass Agri stupid af shjt/Reference/TomQuality.csv\",\n",
    "    \"GreenhouseClimate\": \"D:/Bitchass Agri stupid af shjt/Reference/GreenhouseClimate.csv\",\n",
    "    \"GrodanSens\": \"D:/Bitchass Agri stupid af shjt/Reference/GrodanSens.csv\",\n",
    "    \"Resources\": \"D:/Bitchass Agri stupid af shjt/Reference/Resources.csv\",\n",
    "    \"Weather\": \"D:/Bitchass Agri stupid af shjt/Weather/Weather.csv\",\n",
    "    \"CropParameters\": \"D:/Bitchass Agri stupid af shjt/Reference/CropParameters.csv\",\n",
    "    \"Production\": \"D:/Bitchass Agri stupid af shjt/Reference/Production.csv\"\n",
    "}"
   ],
   "id": "6c35c3cb99f54b66",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:01.457450Z",
     "start_time": "2025-05-23T10:38:00.381341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfs = {}\n",
    "for name, path in file_paths.items():\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    df.columns = df.columns.str.strip().str.replace('\\t', '')\n",
    "    # === Safe and robust date parsing ===\n",
    "    if name == 'TomQuality':\n",
    "        # Use index as the true datetime source\n",
    "        df.reset_index(inplace=True)\n",
    "        df['Date'] = pd.to_datetime(df['index'], origin='1899-12-30', unit='D')\n",
    "    elif '%time' in df.columns:\n",
    "        df['%time'] = pd.to_numeric(df['%time'], errors='coerce')\n",
    "        df['Date'] = pd.to_datetime(df['%time'], origin='1899-12-30', unit='D')\n",
    "    elif 'time' in df.columns:\n",
    "        df['time'] = pd.to_numeric(df['time'], errors='coerce')\n",
    "        df['Date'] = pd.to_datetime(df['time'], origin='1899-12-30', unit='D')\n",
    "    elif 'Date' in df.columns:\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    else:\n",
    "        df['Date'] = pd.NaT  # Fallback if no date column\n",
    "    # Convert all columns except Date to numeric\n",
    "    df.loc[:, df.columns != 'Date'] = df.loc[:, df.columns != 'Date'].apply(pd.to_numeric, errors='coerce')\n",
    "    dfs[name] = df"
   ],
   "id": "b00cbee80faaa6fb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:01.504036Z",
     "start_time": "2025-05-23T10:38:01.490664Z"
    }
   },
   "cell_type": "code",
   "source": "print(dfs['TomQuality'][['index', 'Date']].head())",
   "id": "fcd9904f4502f152",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index       Date\n",
      "0  43880 2020-02-19\n",
      "1  43894 2020-03-04\n",
      "2  43908 2020-03-18\n",
      "3  43922 2020-04-01\n",
      "4  43936 2020-04-15\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:01.550627Z",
     "start_time": "2025-05-23T10:38:01.537272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "soil_cols = ['EC_slab1', 'EC_slab2', 'WC_slab1', 'WC_slab2', 't_slab1', 't_slab2']\n",
    "indoor_cols = ['Tair', 'Rhair', 'CO2air', 'HumDef', 'PipeLow', 'VentLee', 'Ventwind', 'Tot_PAR', 'Tot_PAR_Lamps', 'EC_drain_PC']\n",
    "weather_cols = ['Tout', 'Rhout', 'Iglob', 'PARout', 'Pyrgeo', 'Rain', 'Winddir', 'Windsp']\n",
    "crop_cols = ['Stem_elong', 'Stem_thick', 'Cum_trusses', 'stem_dens', 'plant_dens']\n",
    "prod_cols = ['ProdA', 'ProdB', 'Weight_fruits_ClassA', 'avg_nr_harvested_trusses']\n",
    "target_cols = ['Flavour', 'TSS', 'Acid', '%Juice', 'Bite', 'WeightDMC_fruit']"
   ],
   "id": "8663c1bb4abe6541",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:01.595888Z",
     "start_time": "2025-05-23T10:38:01.581679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reshape_sliding(df, cols, steps, stride=1):\n",
    "    df = df.copy()\n",
    "    df[cols] = df[cols].astype(np.float32)\n",
    "    arr = df[cols].values\n",
    "    if len(arr) < steps:\n",
    "        return np.empty((0, steps, len(cols)))\n",
    "    windows = [arr[i:i + steps] for i in range(0, len(arr) - steps + 1, stride)]\n",
    "    return np.stack(windows)"
   ],
   "id": "1a418929ad2cbd45",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:01.627465Z",
     "start_time": "2025-05-23T10:38:01.613424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_delta(mask):\n",
    "    B, T, D = mask.shape\n",
    "    delta = np.zeros((B, T, D), dtype=np.float32)\n",
    "    for b in range(B):\n",
    "        for d in range(D):\n",
    "            last_obs = 0\n",
    "            for t in range(T):\n",
    "                if mask[b, t, d] == 1:\n",
    "                    delta[b, t, d] = 0\n",
    "                    last_obs = 0\n",
    "                else:\n",
    "                    last_obs += 1\n",
    "                    delta[b, t, d] = last_obs\n",
    "    return delta"
   ],
   "id": "11d262616ad1269d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:01.937268Z",
     "start_time": "2025-05-23T10:38:01.659241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start with GrodanSens as the high-res base\n",
    "base = dfs['GrodanSens'].copy()\n",
    "base = base.dropna(subset=['Date']).sort_values('Date').reset_index(drop=True)\n",
    "# Define merge partners and their tolerances (1 day is safe for most)\n",
    "merge_partners = ['GreenhouseClimate', 'Weather', 'Production', 'CropParameters']\n",
    "for name in merge_partners:\n",
    "    df = dfs[name].copy()\n",
    "    # Clean and sort\n",
    "    df = df.dropna(subset=['Date']).sort_values('Date')\n",
    "    if '%time' in df.columns:\n",
    "        df.drop(columns=['%time'], inplace=True)\n",
    "    try:\n",
    "        base = pd.merge_asof(\n",
    "            base, df,\n",
    "            on='Date',\n",
    "            direction='nearest',\n",
    "            tolerance=pd.Timedelta('1D')\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"[ERROR] Skipped {name} during merge: {e}\")\n",
    "        continue"
   ],
   "id": "ea733b5f3ccd54bb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:02.060774Z",
     "start_time": "2025-05-23T10:38:01.968694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge TomQuality separately with wider tolerance (2 days)\n",
    "df_tom = dfs['TomQuality'].copy()\n",
    "df_tom = df_tom.dropna(subset=['Date']).sort_values('Date')\n",
    "if '%time' in df_tom.columns:\n",
    "    df_tom.drop(columns=['%time'], inplace=True)\n",
    "try:\n",
    "    base = pd.merge_asof(\n",
    "        base, df_tom,\n",
    "        on='Date',\n",
    "        direction='nearest',\n",
    "        tolerance=pd.Timedelta('2D')\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"[ERROR] Skipped TomQuality during merge: {e}\")"
   ],
   "id": "44f3621264dbeadd",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:02.213964Z",
     "start_time": "2025-05-23T10:38:02.108682Z"
    }
   },
   "cell_type": "code",
   "source": "base = base.dropna(subset=['Date']).reset_index(drop=True)",
   "id": "a75ac43f8be6cc6e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:04.109737Z",
     "start_time": "2025-05-23T10:38:02.262077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "soil_data = reshape_sliding(base, soil_cols, steps=20, stride=1)\n",
    "soil_mask = (~np.isnan(soil_data)).astype(np.float32)\n",
    "soil_delta = compute_delta(soil_mask)\n",
    "soil_data = np.nan_to_num(soil_data)\n",
    "indoor_data = reshape_sliding(base, indoor_cols, steps=20, stride=1)\n",
    "weather_data = reshape_sliding(base, weather_cols, steps=10, stride=1)\n",
    "prod_data = reshape_sliding(base, prod_cols, steps=10, stride=1)\n",
    "crop_data = reshape_sliding(base, crop_cols, steps=1, stride=1).squeeze(1)"
   ],
   "id": "42011d3421f68fdc",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:21.472714Z",
     "start_time": "2025-05-23T10:38:04.157747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Full list of possible end dates\n",
    "window_end_dates = base['Date'].iloc[19:].reset_index(drop=True)\n",
    "targets = []\n",
    "valid_indices = []\n",
    "# Loop only over the number of available soil windows\n",
    "for i in range(len(soil_data)):\n",
    "    end_date = window_end_dates[i]\n",
    "    match = dfs['TomQuality'][(dfs['TomQuality']['Date'] - end_date).abs() <= pd.Timedelta('2D')]\n",
    "    if not match.empty:\n",
    "        targets.append(match[target_cols].values[0].astype(np.float32))\n",
    "        valid_indices.append(i)"
   ],
   "id": "308b1aaab5f20db4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:21.549295Z",
     "start_time": "2025-05-23T10:38:21.519589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if valid_indices:\n",
    "    soil_data = soil_data[valid_indices]\n",
    "    soil_mask = soil_mask[valid_indices]\n",
    "    soil_delta = soil_delta[valid_indices]\n",
    "    indoor_data = indoor_data[valid_indices]\n",
    "    weather_data = weather_data[valid_indices]\n",
    "    prod_data = prod_data[valid_indices]\n",
    "    crop_data = crop_data[valid_indices]\n",
    "    targets = torch.tensor(np.array(targets), dtype=torch.float32)\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(soil_data, dtype=torch.float32),\n",
    "        torch.tensor(soil_mask, dtype=torch.float32),\n",
    "        torch.tensor(soil_delta, dtype=torch.float32),\n",
    "        torch.tensor(indoor_data, dtype=torch.float32),\n",
    "        torch.tensor(weather_data, dtype=torch.float32),\n",
    "        torch.tensor(crop_data, dtype=torch.float32),\n",
    "        torch.tensor(prod_data, dtype=torch.float32),\n",
    "        targets\n",
    ")\n",
    "    dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "    print(f\"Dataloader ready: {len(dataset)} labeled windows matched with TomQuality\")\n",
    "else:\n",
    "    print(\"No labeled windows found.\")"
   ],
   "id": "8c7f677c496244d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader ready: 8936 labeled windows matched with TomQuality\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:21.625780Z",
     "start_time": "2025-05-23T10:38:21.610647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_batch = next(iter(dataloader))\n",
    "soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, prod_x, targets = sample_batch"
   ],
   "id": "f7cfb89abb451a44",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:21.733466Z",
     "start_time": "2025-05-23T10:38:21.719466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check shapes\n",
    "print(f\"Soil shape: {soil_x.shape}\")\n",
    "print(f\"Soil mask shape: {soil_mask.shape}\")\n",
    "print(f\"Soil delta shape: {soil_delta.shape}\")\n",
    "print(f\"Indoor shape: {indoor_x.shape}\")\n",
    "print(f\"Weather shape: {weather_x.shape}\")\n",
    "print(f\"Crop shape: {crop_x.shape}\")\n",
    "print(f\"Production shape: {prod_x.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")"
   ],
   "id": "b05bad88e21165a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soil shape: torch.Size([8, 20, 6])\n",
      "Soil mask shape: torch.Size([8, 20, 6])\n",
      "Soil delta shape: torch.Size([8, 20, 6])\n",
      "Indoor shape: torch.Size([8, 20, 10])\n",
      "Weather shape: torch.Size([8, 10, 8])\n",
      "Crop shape: torch.Size([8, 5])\n",
      "Production shape: torch.Size([8, 10, 4])\n",
      "Targets shape: torch.Size([8, 6])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:21.842037Z",
     "start_time": "2025-05-23T10:38:21.828024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lengths\n",
    "total_len = len(dataset)\n",
    "train_len = int(0.8 * total_len)\n",
    "val_len = int(0.1 * total_len)\n",
    "test_len = total_len - train_len - val_len  # handle rounding\n",
    "# Split dataset\n",
    "train, val, test = random_split(dataset, [train_len, val_len, test_len])\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test, batch_size=8, shuffle=False)\n",
    "print(f\"Split sizes — Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")"
   ],
   "id": "c09eecadca059110",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes — Train: 7148, Val: 893, Test: 895\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "97c4cea9d8d2412d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:21.951014Z",
     "start_time": "2025-05-23T10:38:21.936597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GRUD(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=None, device=\"cpu\"):\n",
    "        super(GRUD, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.gamma_x = nn.Parameter(torch.Tensor(input_size))\n",
    "        self.gamma_h = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        self.z_gate = nn.Linear(input_size * 3 + hidden_size, hidden_size)\n",
    "        self.r_gate = nn.Linear(input_size * 3 + hidden_size, hidden_size)\n",
    "        self.h_tilde = nn.Linear(input_size * 3 + hidden_size, hidden_size)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size, output_size) if output_size else nn.Identity()\n",
    "        )\n",
    "        self.reset_parameters()\n",
    "    def reset_parameters(self):\n",
    "        nn.init.constant_(self.gamma_x, 0.1)\n",
    "        nn.init.constant_(self.gamma_h, 0.1)\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name and param.dim() > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "    def forward(self, x, x_mask, x_delta, x_mean=None):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        if x_mean is None:\n",
    "            x_mean = torch.mean(x, dim=1, keepdim=True).detach()\n",
    "        h = torch.zeros(batch_size, self.hidden_size, device=self.device)\n",
    "        outputs = []\n",
    "        gamma_h = torch.exp(-F.relu(self.gamma_h)).unsqueeze(0).expand(batch_size, -1)\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]\n",
    "            m_t = x_mask[:, t, :]\n",
    "            d_t = x_delta[:, t, :]\n",
    "            gamma_x = torch.exp(-F.relu(self.gamma_x) * d_t)\n",
    "            x_t_hat = m_t * x_t + (1 - m_t) * (gamma_x * x_t + (1 - gamma_x) * x_mean.squeeze(1))\n",
    "            h = gamma_h * h\n",
    "            inputs = torch.cat([x_t_hat, m_t, d_t, h], dim=1)\n",
    "            z = torch.sigmoid(self.z_gate(inputs))\n",
    "            r = torch.sigmoid(self.r_gate(inputs))\n",
    "            h_tilde = torch.tanh(self.h_tilde(torch.cat([x_t_hat, m_t, d_t, r * h], dim=1)))\n",
    "            h = (1 - z) * h + z * h_tilde\n",
    "            outputs.append(h.unsqueeze(1))\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return self.output(outputs[:, -1, :])"
   ],
   "id": "fd7c1a7cbd46f7e6",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:22.059909Z",
     "start_time": "2025-05-23T10:38:22.045489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ],
   "id": "12b43d5d9db9a2a2",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:22.168379Z",
     "start_time": "2025-05-23T10:38:22.153740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, input_channels, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        #[B, C, T]\n",
    "        return self.net(x)"
   ],
   "id": "cee28d10bd48b675",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:22.275546Z",
     "start_time": "2025-05-23T10:38:22.261590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, h_n = self.gru(x)\n",
    "        return self.linear(h_n.squeeze(0))"
   ],
   "id": "70cc47165e91a792",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:22.382994Z",
     "start_time": "2025-05-23T10:38:22.368592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AttentionFusion(nn.Module):\n",
    "    def __init__(self, input_dims, fused_dim):\n",
    "        \"\"\"\n",
    "        input_dims: list of dims from each modality (e.g., [64, 64, 32, 64, 32])\n",
    "        fused_dim: output dimension after fusion\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.target_dim = max(input_dims)\n",
    "        self.proj = nn.ModuleList([nn.Linear(d, self.target_dim) for d in input_dims])\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=self.target_dim, num_heads=1, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(self.target_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.project = nn.Linear(self.target_dim, fused_dim)\n",
    "    def forward(self, embeddings):\n",
    "        # Project all embeddings to common dimension\n",
    "        projected = [proj(x) for proj, x in zip(self.proj, embeddings)]  # [B, D_i] → [B, target_dim]\n",
    "        x = torch.stack(projected, dim=1)  # [B, num_modalities, target_dim]\n",
    "        attn_output, _ = self.attn(x, x, x)\n",
    "        attn_output = self.norm(attn_output + x)\n",
    "        pooled = attn_output.mean(dim=1)\n",
    "        return self.project(self.dropout(pooled))"
   ],
   "id": "2d1500895c9aaa28",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:22.489517Z",
     "start_time": "2025-05-23T10:38:22.477495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PredictionHead(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),  # Improves stability during training\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, output_dim)  # Matches config['num_targets']\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.head(x)"
   ],
   "id": "6d949d9117b703d1",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:40:06.992899Z",
     "start_time": "2025-05-23T10:40:06.984767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HybridAgriModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.grud = GRUD(config['soil_in'], config['soil_hidden'], config['soil_out'], config['device'])\n",
    "        self.indoor_encoder = GRUEncoder(config['indoor_in'], config['indoor_hidden'], config['indoor_out'])  # Placeholder for TimesNet\n",
    "        self.weather_encoder = CNN1D(config['weather_in'], config['weather_out'])\n",
    "        self.crop_encoder = MLPBlock(config['crop_in'], 64, config['crop_out'])\n",
    "        self.prod_encoder = GRUEncoder(config['prod_in'], config['prod_hidden'], config['prod_out'])\n",
    "        self.fusion = AttentionFusion([\n",
    "            config['soil_out'], config['indoor_out'], config['weather_out'], config['crop_out'], config['prod_out']\n",
    "        ], config['fused_dim'])\n",
    "        self.head = PredictionHead(config['fused_dim'], config['num_targets'])\n",
    "\n",
    "    def forward(self, soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, prod_x):\n",
    "        h_soil = self.grud(soil_x, soil_mask, soil_delta)  # Last time step\n",
    "        h_indoor = self.indoor_encoder(indoor_x)\n",
    "        h_weather = self.weather_encoder(weather_x.transpose(1, 2))\n",
    "        h_crop = self.crop_encoder(crop_x)\n",
    "        h_prod = self.prod_encoder(prod_x)\n",
    "        fused = self.fusion([h_soil, h_indoor, h_weather, h_crop, h_prod])\n",
    "        return self.head(fused)"
   ],
   "id": "1b7ab3ff8d90c88e",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:22.706575Z",
     "start_time": "2025-05-23T10:38:22.693317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_virtual = {\n",
    "    'soil_in': 6, 'soil_hidden': 64, 'soil_out': 64,\n",
    "    'indoor_in': 10, 'indoor_hidden': 64, 'indoor_out': 64,\n",
    "    'weather_in': 8, 'weather_out': 64,\n",
    "    'crop_in': 5, 'crop_out': 64,\n",
    "    'prod_in': 4, 'prod_hidden': 64, 'prod_out': 64,\n",
    "    'fused_dim': 128, 'num_targets': 6,\n",
    "    'device': 'cpu'\n",
    "}\n",
    "\n",
    "# === Dummy inputs that reflect your DataLoader ===\n",
    "B = 8\n",
    "sample_inputs = (\n",
    "    torch.rand(B, 20, config_virtual['soil_in']),       # soil_x\n",
    "    torch.ones(B, 20, config_virtual['soil_in']),       # soil_mask\n",
    "    torch.zeros(B, 20, config_virtual['soil_in']),      # soil_delta\n",
    "    torch.rand(B, 20, config_virtual['indoor_in']),     # indoor_x\n",
    "    torch.rand(B, config_virtual['weather_in'], 10),    # weather_x\n",
    "    torch.rand(B, config_virtual['crop_in']),           # crop_x\n",
    "    torch.rand(B, 10, config_virtual['prod_in'])        # prod_x\n",
    ")"
   ],
   "id": "f47b1bbd1e7467d9",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:22.830362Z",
     "start_time": "2025-05-23T10:38:22.816649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_model_structure(model, sample_inputs):\n",
    "    print(\"Model Architecture Validation:\\n\")\n",
    "    logs = []\n",
    "\n",
    "    def safe_shape(x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return list(x.shape)\n",
    "        elif isinstance(x, (list, tuple)) and isinstance(x[0], torch.Tensor):\n",
    "            return [list(t.shape) for t in x]\n",
    "        return str(type(x))\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        logs.append({\n",
    "            \"layer\": module.__class__.__name__,\n",
    "            \"input_shape\": safe_shape(input),\n",
    "            \"output_shape\": safe_shape(output)\n",
    "        })\n",
    "\n",
    "    hooks = [m.register_forward_hook(hook_fn) for m in model.modules()\n",
    "             if not isinstance(m, (nn.Sequential, nn.ModuleList)) and m != model]\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        model(*sample_inputs)\n",
    "\n",
    "    for i, log in enumerate(logs):\n",
    "        print(f\"{i:02d} - {log['layer']:20} | Input: {log['input_shape']} -> Output: {log['output_shape']}\")\n",
    "    for h in hooks:\n",
    "        h.remove()"
   ],
   "id": "5ea8d258ee6e1659",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:38:22.969164Z",
     "start_time": "2025-05-23T10:38:22.939388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = HybridAgriModel(config_virtual)\n",
    "validate_model_structure(model, sample_inputs)"
   ],
   "id": "b3afcc40a8b34835",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture Validation:\n",
      "\n",
      "00 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "01 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "02 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "03 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "04 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "05 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "06 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "07 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "08 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "09 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "10 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "11 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "12 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "13 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "14 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "15 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "16 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "17 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "18 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "19 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "20 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "21 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "22 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "23 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "24 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "25 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "26 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "27 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "28 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "29 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "30 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "31 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "32 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "33 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "34 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "35 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "36 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "37 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "38 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "39 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "40 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "41 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "42 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "43 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "44 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "45 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "46 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "47 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "48 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "49 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "50 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "51 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "52 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "53 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "54 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "55 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "56 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "57 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "58 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "59 - Linear               | Input: [[8, 82]] -> Output: [8, 64]\n",
      "60 - LayerNorm            | Input: [[8, 64]] -> Output: [8, 64]\n",
      "61 - Dropout              | Input: [[8, 64]] -> Output: [8, 64]\n",
      "62 - Linear               | Input: [[8, 64]] -> Output: [8, 64]\n",
      "63 - GRUD                 | Input: [[8, 20, 6], [8, 20, 6], [8, 20, 6]] -> Output: [8, 64]\n",
      "64 - GRU                  | Input: [[8, 20, 10]] -> Output: [[8, 20, 64], [1, 8, 64]]\n",
      "65 - Linear               | Input: [[8, 64]] -> Output: [8, 64]\n",
      "66 - GRUEncoder           | Input: [[8, 20, 10]] -> Output: [8, 64]\n",
      "67 - Conv1d               | Input: [[8, 8, 10]] -> Output: [8, 32, 10]\n",
      "68 - ReLU                 | Input: [[8, 32, 10]] -> Output: [8, 32, 10]\n",
      "69 - AdaptiveAvgPool1d    | Input: [[8, 32, 10]] -> Output: [8, 32, 1]\n",
      "70 - Flatten              | Input: [[8, 32, 1]] -> Output: [8, 32]\n",
      "71 - Linear               | Input: [[8, 32]] -> Output: [8, 64]\n",
      "72 - CNN1D                | Input: [[8, 8, 10]] -> Output: [8, 64]\n",
      "73 - Linear               | Input: [[8, 5]] -> Output: [8, 64]\n",
      "74 - ReLU                 | Input: [[8, 64]] -> Output: [8, 64]\n",
      "75 - Dropout              | Input: [[8, 64]] -> Output: [8, 64]\n",
      "76 - Linear               | Input: [[8, 64]] -> Output: [8, 64]\n",
      "77 - MLPBlock             | Input: [[8, 5]] -> Output: [8, 64]\n",
      "78 - GRU                  | Input: [[8, 10, 4]] -> Output: [[8, 10, 64], [1, 8, 64]]\n",
      "79 - Linear               | Input: [[8, 64]] -> Output: [8, 64]\n",
      "80 - GRUEncoder           | Input: [[8, 10, 4]] -> Output: [8, 64]\n",
      "81 - Linear               | Input: [[8, 64]] -> Output: [8, 64]\n",
      "82 - Linear               | Input: [[8, 64]] -> Output: [8, 64]\n",
      "83 - Linear               | Input: [[8, 64]] -> Output: [8, 64]\n",
      "84 - Linear               | Input: [[8, 64]] -> Output: [8, 64]\n",
      "85 - Linear               | Input: [[8, 64]] -> Output: [8, 64]\n",
      "86 - MultiheadAttention   | Input: [[8, 5, 64], [8, 5, 64], [8, 5, 64]] -> Output: [[8, 5, 64], [8, 5, 5]]\n",
      "87 - LayerNorm            | Input: [[8, 5, 64]] -> Output: [8, 5, 64]\n",
      "88 - Dropout              | Input: [[8, 64]] -> Output: [8, 64]\n",
      "89 - Linear               | Input: [[8, 64]] -> Output: [8, 128]\n",
      "90 - AttentionFusion      | Input: <class 'tuple'> -> Output: [8, 128]\n",
      "91 - Linear               | Input: [[8, 128]] -> Output: [8, 128]\n",
      "92 - BatchNorm1d          | Input: [[8, 128]] -> Output: [8, 128]\n",
      "93 - ReLU                 | Input: [[8, 128]] -> Output: [8, 128]\n",
      "94 - Dropout              | Input: [[8, 128]] -> Output: [8, 128]\n",
      "95 - Linear               | Input: [[8, 128]] -> Output: [8, 6]\n",
      "96 - PredictionHead       | Input: [[8, 128]] -> Output: [8, 6]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train this bitchass",
   "id": "5f55a8ea403b650d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:40:13.275248Z",
     "start_time": "2025-05-23T10:40:13.258260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "config_real = {\n",
    "    'soil_in': 6, 'soil_hidden': 64, 'soil_out': 64,\n",
    "    'indoor_in': 10, 'indoor_hidden': 64, 'indoor_out': 64,\n",
    "    'weather_in': 8, 'weather_out': 32,\n",
    "    'crop_in': 5, 'crop_out': 32,\n",
    "    'prod_in': 4, 'prod_hidden': 64, 'prod_out': 64,\n",
    "    'fused_dim': 128, 'num_targets': 6,\n",
    "    'device': device\n",
    "}"
   ],
   "id": "2b6df29301ba5d0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:40:14.375733Z",
     "start_time": "2025-05-23T10:40:14.353125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = HybridAgriModel(config_real).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "epochs = 100"
   ],
   "id": "9db174af56678db0",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:40:15.536853Z",
     "start_time": "2025-05-23T10:40:15.525348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(loader, desc=\"Train\"):\n",
    "        soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, prod_x, y = [b.to(device) for b in batch]\n",
    "        optimizer.zero_grad()\n",
    "        out = model(soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, prod_x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ],
   "id": "3c18dc82656217d3",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:40:16.725012Z",
     "start_time": "2025-05-23T10:40:16.714634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate(loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Val\"):\n",
    "            soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, prod_x, y = [b.to(device) for b in batch]\n",
    "            out = model(soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, prod_x)\n",
    "            loss = criterion(out, y)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(loader)"
   ],
   "id": "4badae16ae9430b6",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:40:18.120264Z",
     "start_time": "2025-05-23T10:40:18.107105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Test\"):\n",
    "            soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, prod_x, y = [b.to(device) for b in batch]\n",
    "            out = model(soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, prod_x)\n",
    "            preds.append(out.cpu().numpy())\n",
    "            targets.append(y.cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    targets = np.concatenate(targets)\n",
    "    mse = mean_squared_error(targets, preds)\n",
    "    mae = mean_absolute_error(targets, preds)\n",
    "    print(f\"\\nTest MSE: {mse:.4f}, MAE: {mae:.4f}\")"
   ],
   "id": "9d9c838500987729",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T10:45:20.317058Z",
     "start_time": "2025-05-23T10:40:19.397459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train_one_epoch(train_loader)\n",
    "    val_loss = validate(val_loader)\n",
    "    print(f\"[Epoch {epoch:03}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")"
   ],
   "id": "cd5681b7bfb605fd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 894/894 [00:35<00:00, 24.92it/s]\n",
      "Val: 100%|██████████| 112/112 [00:01<00:00, 69.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] Train Loss: nan | Val Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 894/894 [00:36<00:00, 24.37it/s]\n",
      "Val: 100%|██████████| 112/112 [00:01<00:00, 69.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 002] Train Loss: nan | Val Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 894/894 [00:38<00:00, 23.25it/s]\n",
      "Val: 100%|██████████| 112/112 [00:01<00:00, 69.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 003] Train Loss: nan | Val Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 894/894 [00:37<00:00, 23.59it/s]\n",
      "Val: 100%|██████████| 112/112 [00:01<00:00, 69.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 004] Train Loss: nan | Val Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 894/894 [00:37<00:00, 23.77it/s]\n",
      "Val: 100%|██████████| 112/112 [00:01<00:00, 65.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 005] Train Loss: nan | Val Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 894/894 [00:38<00:00, 23.47it/s]\n",
      "Val: 100%|██████████| 112/112 [00:01<00:00, 66.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 006] Train Loss: nan | Val Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 894/894 [00:37<00:00, 23.72it/s]\n",
      "Val: 100%|██████████| 112/112 [00:01<00:00, 64.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 007] Train Loss: nan | Val Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  70%|███████   | 627/894 [00:26<00:11, 23.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[40], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m----> 2\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     val_loss \u001B[38;5;241m=\u001B[39m validate(val_loader)\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] Train Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m | Val Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[37], line 7\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(loader)\u001B[0m\n\u001B[0;32m      5\u001B[0m soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, prod_x, y \u001B[38;5;241m=\u001B[39m [b\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m batch]\n\u001B[0;32m      6\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 7\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43msoil_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msoil_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msoil_delta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindoor_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweather_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcrop_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprod_x\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(out, y)\n\u001B[0;32m      9\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ImFucked\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ImFucked\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[34], line 15\u001B[0m, in \u001B[0;36mHybridAgriModel.forward\u001B[1;34m(self, soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, prod_x)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, soil_x, soil_mask, soil_delta, indoor_x, weather_x, crop_x, prod_x):\n\u001B[1;32m---> 15\u001B[0m     h_soil \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrud\u001B[49m\u001B[43m(\u001B[49m\u001B[43msoil_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msoil_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msoil_delta\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Last time step\u001B[39;00m\n\u001B[0;32m     16\u001B[0m     h_indoor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindoor_encoder(indoor_x)\n\u001B[0;32m     17\u001B[0m     h_weather \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweather_encoder(weather_x\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m))\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ImFucked\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ImFucked\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[18], line 38\u001B[0m, in \u001B[0;36mGRUD.forward\u001B[1;34m(self, x, x_mask, x_delta, x_mean)\u001B[0m\n\u001B[0;32m     36\u001B[0m x_t_hat \u001B[38;5;241m=\u001B[39m m_t \u001B[38;5;241m*\u001B[39m x_t \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m m_t) \u001B[38;5;241m*\u001B[39m (gamma_x \u001B[38;5;241m*\u001B[39m x_t \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m gamma_x) \u001B[38;5;241m*\u001B[39m x_mean\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m     37\u001B[0m h \u001B[38;5;241m=\u001B[39m gamma_h \u001B[38;5;241m*\u001B[39m h\n\u001B[1;32m---> 38\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx_t_hat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mm_t\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md_t\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m z \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msigmoid(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mz_gate(inputs))\n\u001B[0;32m     40\u001B[0m r \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msigmoid(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mr_gate(inputs))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evaluate(test_loader)",
   "id": "7739d9604726d657",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
